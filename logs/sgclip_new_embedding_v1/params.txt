batch_size: 64
beta1: 0.9
beta2: 0.999
checkpoint_path: ./logs/sgclip_new_embedding_v1/checkpoints
ddp_static_graph: False
debug: False
device: cuda:0
dist_backend: nccl
dist_url: env://
distributed: False
embed_dim: 512
epochs: 100
eps: 1e-08
force_quick_gelu: False
gather_with_grad: False
grad_checkpointing: False
graph_width: 512
image_mean: None
image_size: 224
image_std: None
include_relationships: True
local_loss: False
local_rank: 0
lock_image: False
lock_image_freeze_bn_stats: False
lock_image_unlocked_groups: 0
log_level: 20
log_local: False
log_path: ./logs/sgclip_new_embedding_v1/out.log
logs: ./logs/
lr: 0.0005
max_objects_per_image: 10
model_config_json: 
name: sgclip_new_embedding_v1
no_set_device_rank: False
norm_gradient_clip: None
num_graph_layer: 5
precision: amp
pretrained: 
pretrained_image: False
rank: 0
report_to: 
resume: logs/sgclip_new_embedding_v1/checkpoints/epoch_12.pt
save_frequency: 1
save_most_recent: False
seed: 9768
skip_scheduler: False
tensorboard: False
tensorboard_path: 
train_data: ./datasets/vg/images
train_h5: ./datasets/vg/train.h5
use_bn_sync: False
use_orphaned_objects: True
val_batch_size: 128
val_frequency: 1
val_h5: ./datasets/vg/val.h5
vocab_json: ./datasets/vg/vocab.json
warmup: 10000
wd: 0.2
workers: 1
world_size: 1
